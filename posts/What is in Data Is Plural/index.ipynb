{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afb0f6ee-7b43-42d8-a97e-9812391bbf55",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"What is in Data Is Plural?\"\n",
    "date: \"2023-11-06\"\n",
    "categories: [EDA, LLM]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e030bedf-b431-476e-bf33-2c558d3b45d1",
   "metadata": {},
   "source": [
    "![DIP](https://fivethirtyeight.com/wp-content/uploads/2022/05/DATA-IS-PLURAL-3-4x3-1.png?w=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc07b6-ffc9-4028-8aa7-2e8e85607ed4",
   "metadata": {},
   "source": [
    "At What Can Data Do?, we delve into the wealth of data found in [Data is Plural](https://www.data-is-plural.com/), a weekly newsletter by Jeremy Singer-Vine that showcases a rich selection of datasets. As a long-time admirer, I often turn to this resource when seeking out well-curated data for my research. Jeremy's compilation boasts over 1,750 datasets and continues to expand each week.\n",
    "\n",
    "One challenge I've encountered is navigating the archive—it's not the most search-friendly. While Jeremy provides a Google Sheet with details on the featured datasets, it doesn't quite facilitate inquiries such as: **\"Which datasets in the archive relate to global energy production?\"**\n",
    "\n",
    "To address this, I embarked on enhancing the archive's searchability. By applying semantic search to the entirety of Data is Plural's publications, my goal was not only to learn but also to forge a tool that elevates the ease of data discovery. Let's dive in..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c4a2d-72ea-4ee5-9982-88cfe7162dad",
   "metadata": {},
   "source": [
    "### What is Semantic Search\n",
    "Semantic search transcends the traditional keyword match, delving into the intent and contextual nuance behind a query to fetch the most pertinent information. Rather than simply scanning for specific terms, it employs sophisticated cognitive tools to consider elements such as:\n",
    "\n",
    "- **Contextual Understanding**: Words shift in meaning based on their use. Semantic search aims to grasp this context, refining its accuracy.\n",
    "\n",
    "- **Recognition of Synonyms**: It appreciates that different terms can share meanings and provides relevant findings even when exact search terms are absent from the content.\n",
    "\n",
    "- **Natural Language Processing (NLP)**: Utilizing NLP, semantic search interprets the searcher's intent, managing conversational queries with finesse.\n",
    "\n",
    "- **Conceptual Insight**: It searches for ideas and meanings rather than just phrase matches, capturing the essence behind the words.\n",
    "\n",
    "- **Discerning User Intent**: Semantic search adjusts results to align with whether a user aims to purchase, explore, locate, or troubleshoot.\n",
    "\n",
    "- **Tailored Results**: It may also integrate personal data like past behavior, locale, or time, to customize the search experience.\n",
    "\n",
    "Powered by machine learning, ontologies, and NLP, semantic search is adept at closing the gap between what users seek and the content they find. This technology proves invaluable in customer support, e-commerce, knowledge management, and content discovery, ensuring users connect more intuitively with the information they require.\n",
    "\n",
    "### What is the all-mpnet-base scentence transformer and how does it work?\n",
    "The `all-mpnet-base-v2` is a pre-trained model provided by the Hugging Face Sentence Transformers library, which is a Python framework for state-of-the-art sentence, text, and image embeddings. The model is based on the MPNet architecture, which stands for [\"Masked and Permuted Pre-training for Language Understanding.\"](https://arxiv.org/abs/2004.09297)\n",
    "\n",
    "MPNet is an innovative pre-training method that combines the strengths of BERT ([Bidirectional Encoder Representations from Transformers](https://arxiv.org/abs/1810.04805)) and [XLNet architectures](https://arxiv.org/abs/1906.08237) to effectively capture the contextual representations of words in a sentence. The MPNet is designed to understand the context from both the left and right sides of a token in the input sequence.\n",
    "\n",
    "Here's how the `all-mpnet-base-v2` model works in the context of sentence transformers:\n",
    "\n",
    "1. **Pre-training:**\n",
    "   - MPNet is pre-trained on a large corpus of text data using self-supervised learning. It uses a novel pre-training objective that masks some of the input tokens and permutes others, allowing the model to learn a deep understanding of language context and word relationships.\n",
    "\n",
    "2. **Sentence Embeddings:**\n",
    "   - The `all-mpnet-base-v2` model is fine-tuned to produce sentence embeddings. This means that for any given sentence or paragraph, the model generates a fixed-size vector representation that captures its semantic meaning. These embeddings can be used for a variety of downstream tasks such as semantic search, clustering, and classification.\n",
    "   \n",
    "3. **Fine-tuning for Specific Tasks:**\n",
    "   - Although the model is pre-trained on a general corpus, it can be further fine-tuned on task-specific data to improve performance on particular tasks. For example, if you want to use the model for legal document analysis, you could fine-tune it on a corpus of legal texts.\n",
    "\n",
    "4. **Usage in Applications:**\n",
    "   - In applications, when you input a sentence to the `all-mpnet-base-v2` model, it processes the text through multiple transformer layers, generating an embedding vector that you can then use for semantic comparisons, search, or as input features to other machine learning models.\n",
    "\n",
    "The Sentence Transformers library makes it easy to use these models. You can load the `all-mpnet-base-v2` model and generate embeddings for your sentences with just a few lines of code. These embeddings are designed to be semantically meaningful, such that sentences with similar meanings are close to each other in the embedding space, which is beneficial for many NLP tasks that require understanding sentence similarity.\n",
    "\n",
    "\n",
    "### What is Cosine Simarity and How do I calculate it?\n",
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any other angle.\n",
    "\n",
    "It is thus a judgment of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.\n",
    "\n",
    "Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1]. The cosine similarity, `S`, between two vectors `A` and `B` is calculated as follows:\n",
    "\n",
    "S(A, B) = dot(A,B) / (||A|| * ||B||)\n",
    "\n",
    "where:\n",
    "\n",
    "-  dot(A,B) is the dot product of the vectors,\n",
    "- ||A|| and ||B|| are the norms (magnitudes) of vectors `A` and `B`.\n",
    "\n",
    "This measure is a metric of the cosine of the angle between two n-dimensional vectors in an n-dimensional space. It should not be confused with a physical space, as it can be used for high dimensional spaces, e.g., text classification in an information retrieval context where each term is a dimension and the terms in a document are modeled as a vector for comparison with other documents.\n",
    "\n",
    "### How we are going to apply Semantic Search to the DIP catalog\n",
    "* Use the [Hugging Face](https://huggingface.co/) open source model library\n",
    "* [Use the Sentence Transformer](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#all-mpnet-base-v2) It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "* Use the cosine similarity measure to assess the \"distance\" between the descriptions in the catalog and the posed questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7e00a-9e5f-4cad-8592-9be10b79ff7e",
   "metadata": {},
   "source": [
    "## Step 1 - Install the requisite python libraries needed to do semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cbd276-7b5a-40f5-a88e-56d6276c181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers[torch] torch scikit-learn protobuf==3.20.0 sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ad33e-fb8d-42de-869b-70545bac29d3",
   "metadata": {},
   "source": [
    "## Step 2 - Import the requisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1569e933-3929-47d9-b370-6e9ad528be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985eb1c-5877-44b0-95e1-01f3337f82bd",
   "metadata": {},
   "source": [
    "## Step 3 - Load the Data is Plural Catalog Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0366388-4290-4e3a-adf2-18712fd2030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1750 entries in the Data Is Plural catalog.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edition</th>\n",
       "      <th>position</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>links</th>\n",
       "      <th>hattips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015.10.21</td>\n",
       "      <td>1</td>\n",
       "      <td>Every place name in the United States.</td>\n",
       "      <td>Sometimes, bureaucracy creates poetry. Since 1...</td>\n",
       "      <td>http://geonames.usgs.gov/index.html\\nhttp://ge...</td>\n",
       "      <td>https://twitter.com/emilymbadger/status/653982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015.10.21</td>\n",
       "      <td>2</td>\n",
       "      <td>“There’s finally federal data on low-income co...</td>\n",
       "      <td>The Hechinger Report casts doubt on the Pell g...</td>\n",
       "      <td>http://hechingerreport.org/theres-finally-fede...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015.10.21</td>\n",
       "      <td>3</td>\n",
       "      <td>What police-related data does your city publish?</td>\n",
       "      <td>The Police Open Data Census, created by Code f...</td>\n",
       "      <td>https://codeforamerica.github.io/PoliceOpenDat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      edition  position                                           headline  \\\n",
       "0  2015.10.21         1             Every place name in the United States.   \n",
       "1  2015.10.21         2  “There’s finally federal data on low-income co...   \n",
       "2  2015.10.21         3   What police-related data does your city publish?   \n",
       "\n",
       "                                                text  \\\n",
       "0  Sometimes, bureaucracy creates poetry. Since 1...   \n",
       "1  The Hechinger Report casts doubt on the Pell g...   \n",
       "2  The Police Open Data Census, created by Code f...   \n",
       "\n",
       "                                               links  \\\n",
       "0  http://geonames.usgs.gov/index.html\\nhttp://ge...   \n",
       "1  http://hechingerreport.org/theres-finally-fede...   \n",
       "2  https://codeforamerica.github.io/PoliceOpenDat...   \n",
       "\n",
       "                                             hattips  \n",
       "0  https://twitter.com/emilymbadger/status/653982...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV and preprocess\n",
    "SHEET_ID = '1wZhPLMCHKJvwOkP4juclhjFgqIY8fQFMemwKL2c64vk'\n",
    "SHEET_NAME = 'Items'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}'\n",
    "data_df = pd.read_csv(url)\n",
    "print(f\"There are {len(data_df)} entries in the Data Is Plural catalog.\")\n",
    "# Take a peak at the first several rows of the data\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054301a-ac61-47e7-a66a-fee069f49291",
   "metadata": {},
   "source": [
    "## Step 4 Create descriptions and embedding vectors for each\n",
    "(takes several minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8487cab-ebd1-477c-9ab1-5585c0e0de09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding of 1750 descriptions took  169 seconds to run\n",
      "An example dataset description and its associated embedding...\n",
      "Every place name in the United States. Sometimes, bureaucracy creates poetry. Since 1890, the U.S. Board on Geographic Names has been cataloguing, standardizing, and promulgating official names for the places we hike, swim, work, and call home. Along the way, it began publishing Geographic Names Information System (GNIS), a searchable and downloadable database containing all of its domestic nomenclature. In Alaska alone, the database lists names for 167 dams, 303 post offices, 666 glaciers, 2,704 capes, and 9,575 streams. My favorite: Confusion Creek. [h/t @emilymbadger]\n",
      "The vectors are 768 in length.\n",
      "The first 10 elements of the vector for this description are:\n",
      "tensor([ 0.0570,  0.0512, -0.0187, -0.0174, -0.0091,  0.0062,  0.0331, -0.0004,\n",
      "         0.0364, -0.0083])\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the headlines and description of each dataset in the catalog\n",
    "descriptions = (data_df['headline'] + \" \" + data_df['text']).tolist()\n",
    "\n",
    "# Save the links to each dataset to reference when we are performing the semantic search.\n",
    "links = data_df['links'].tolist()\n",
    "\n",
    "# Load the Sentence Transformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Convert dataset descriptions to embeddings and store them NOT\n",
    "embeddings = model.encode(descriptions, convert_to_tensor=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The embedding of {len(descriptions)} descriptions took {elapsed_time:4.0f} seconds to run\")\n",
    "\n",
    "print(\"An example dataset description and its associated embedding...\")\n",
    "print(descriptions[0])\n",
    "print(f\"The vectors are {len(embeddings[0])} in length.\\nThe first 10 elements of the vector for this description are:\\n{embeddings[0][0:10]}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ef983-026f-4ae0-9132-577d2686e89a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5 Create a utility function that returns the closest matches to a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd20f5f-6253-4370-908e-7470f47cb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes the following arguments:\n",
    " - question (str)\n",
    " - embeddings (tensor)\n",
    " - descriptions (list)\n",
    " - links (list)\n",
    " - top_k (scalar)\n",
    " \n",
    "And returns the top_k closest descriptions to the question that was posed.\n",
    "The routine uses the cosine similarity to assess the \"distance\" between the descriptions of the datasets\n",
    "and the question that was posed.\n",
    "\"\"\"\n",
    "\n",
    "def find_closest_matches(question, embeddings, descriptions, links, top_k=5):\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute cosine similarities\n",
    "    similarities = [util.pytorch_cos_sim(question_embedding, desc_embedding).item() for desc_embedding in embeddings]\n",
    "    \n",
    "    # Get the indices of top matches\n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    return [(descriptions[idx], similarities[idx], links[idx]) for idx in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8af214-f877-48e4-8d2d-9420be3c91ef",
   "metadata": {},
   "source": [
    "## Step 6 Answer questions about the Data Is Plural Catalog\n",
    "return similar datasets to the question including its description and a link to its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "375bd2c7-302e-468f-a027-d16bd57f5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question (or type 'exit' to quit):  What are the datasets that cover manufacturing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top matches:\n",
      "\n",
      "1. Semiconductor logistics. The Emerging Technology Observatory, a new initiative based at Georgetown University, aims to provide a “public platform for high-quality, actionable data resources on the global emerging technology landscape.” Their Advanced Semiconductor Supply Chain Dataset, which you can download and explore online, contains “manually compiled, high-level information about the tools, materials, processes, countries, and firms involved in the production of advanced logic chips.” [h/t Zach Arnold]\n",
      "(Score: 0.6091) References:\n",
      "* https://eto.tech/\n",
      "* https://eto.tech/blog/introducing-emerging-technology-observatory/\n",
      "* https://eto.tech/dataset-docs/chipexplorer/\n",
      "* https://github.com/georgetown-cset/eto-supply-chain/tree/main/data\n",
      "* https://chipexplorer.eto.tech/\n",
      "\n",
      "2. American manufacturing. The Census Bureau’s Annual Survey of Manufacturers provides state-by-state and industry-by-industry statistics for America’s manufacturing sector. Metrics include the number of employees, annual payroll, “value added,” beginning-of-year inventory, and many more. In 2014, dog and cat food manufacturers employed about 18,000 people nationwide. Related: “Why Are Politicians So Obsessed With Manufacturing?” [h/t Scott Stern + RJ Andrews]\n",
      "(Score: 0.5776) References:\n",
      "* http://www.census.gov/programs-surveys/asm.html\n",
      "* http://www.nytimes.com/2016/10/09/magazine/why-are-politicians-so-obsessed-with-manufacturing.html\n",
      "\n",
      "3. The turkey industry. The USDA’s National Agricultural Statistics Service publishes monthly and annual reports estimating the number of turkeys incubating, raised, slaughtered, and in cold storage, based on surveys and food-safety inspections. The reports contain semi-structured data tables, while more-structured data can be fetched through the agency’s Quick Stats tool and API. [h/t Emily Stewart + Walt Hickey]\n",
      "(Score: 0.5385) References:\n",
      "* https://www.nass.usda.gov/\n",
      "* https://usda.library.cornell.edu/concern/publications/k643b117x?locale=en\n",
      "* https://usda.library.cornell.edu/concern/publications/0g354f23n?locale=en\n",
      "* https://usda.library.cornell.edu/concern/publications/3197xm04j?locale=en\n",
      "* https://usda.library.cornell.edu/concern/publications/pg15bd892?locale=en\n",
      "* https://quickstats.nass.usda.gov/\n",
      "* https://quickstats.nass.usda.gov/api/\n",
      "\n",
      "4. Australian mine production. “No […] study has ever compiled a national mine production data set which includes basic mining data such as ore processed, grades, extracted products (e.g., metals, concentrates, saleable ore) and waste rock,” writes Gavin M. Mudd, whose new dataset aims to do exactly that for Australia from 1799 to 2021. It contains mine-by-mine metrics, as well as annual production by state and element/mineral.\n",
      "(Score: 0.5246) References:\n",
      "* https://www.nature.com/articles/s41597-023-02275-z\n",
      "* https://rmit.figshare.com/articles/dataset/A_Comprehensive_Dataset_for_Australian_Mine_Production_1799_to_2021/22724081/2\n",
      "\n",
      "5. Sneaker factories. Nike, Inc.’s manufacturing map displays 618 factories and material suppliers that the company uses to manufacture its products (as of May 2018). You can export the entire dataset, or browse and filter the data online. For each of the factories, the information includes the factory’s name, address, product type, number of workers, percentage of workers who are female, and more. [h/t Marc DaCosta]\n",
      "(Score: 0.5244) References:\n",
      "* http://manufacturingmap.nikeinc.com/\n",
      "\n",
      "6. Offshore drilling. The Bureau of Ocean Energy Management and the Bureau of Safety and Environmental Enforcement — two of the agencies that replaced the troubled U.S. Minerals Management Service in the wake of the Deepwater Horizon spill — publish a few dozen bulk datasets related to their oversight of offshore drilling operations. Among them: lease owners, production metrics, company details, pipeline permits and locations, incident investigations, and platform structures. Related: “American Idle: Decommissioning costs sink offshore drillers into latest crisis,” a 2017 Debtwire investigation that used the platform data. [h/t Alex Plough]\n",
      "(Score: 0.5232) References:\n",
      "* https://www.boem.gov/\n",
      "* https://www.bsee.gov/\n",
      "* https://www.data.bsee.gov/Main/RawData.aspx\n",
      "* https://www.data.bsee.gov/Leasing/LeaseOwner/Default.aspx\n",
      "* https://www.data.bsee.gov/Production/ProductionData/Default.aspx\n",
      "* https://www.data.bsee.gov/Company/CompanyDetail/Default.aspx\n",
      "* https://www.data.bsee.gov/Pipeline/PipelinePermits/Default.aspx\n",
      "* https://www.data.bsee.gov/Pipeline/PipelineLocation/Default.aspx\n",
      "* https://www.data.bsee.gov/Other/DataTables/IncidentInvestigations.aspx\n",
      "* https://www.data.bsee.gov/Platform/PlatformStructures/Default.aspx\n",
      "* http://investigations.debtwire.com/american-idle-decommissioning-costs-sink-offshore-drillers-into-latest-crisis/\n",
      "\n",
      "7. Industrial sector data. Aswath Damodaran — a professor of finance at the NYU’s business school — maintains a trove of data on per-sector financials, including effective tax rates, return on equity, and working capital ratios by industry. For most datasets, Damodaran publishes both current and historical versions. [h/t Tim McGovern]\n",
      "(Score: 0.5144) References:\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/data.html\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/taxrate.htm\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/roe.html\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/wcdata.html\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datacurrent.html\n",
      "* http://pages.stern.nyu.edu/~adamodar/New_Home_Page/dataarchived.html\n",
      "\n",
      "8. Wind turbines. Lawrence Berkeley National Laboratory, the U.S. Geological Survey, and the American Wind Energy Association have partnered to publish the U.S. Wind Turbine Database. The dataset, which the government says will be “continuously updated,” currently contains 57,636 turbines and includes each turbine’s location, development project, manufacturer, model, height, rotor diameter, and other characteristics. You can download the data in several formats, and also explore it on an interactive map. [h/t Ed Vine]\n",
      "(Score: 0.5098) References:\n",
      "* https://eerscmap.usgs.gov/uswtdb/\n",
      "* https://eerscmap.usgs.gov/uswtdb/data/\n",
      "* https://eerscmap.usgs.gov/uswtdb/viewer/\n",
      "\n",
      "9. Nuclear capabilities. The Nuclear Latency Dataset contains “all known uranium enrichment and plutonium reprocessing facilities” built between 1939 and 2012. That amounts to 253 plants around the world, each with information on its construction timeframe, civilian-vs-military purpose, international oversight, and more. [h/t Abraham Epton]\n",
      "(Score: 0.5077) References:\n",
      "* http://www.matthewfuhrmann.com/datasets.html\n",
      "\n",
      "10. FDA inspections. The US Food and Drug Administration’s inspections dashboard lists 264,000+ assessments of facilities (primarily those manufacturing food, drugs, and other FDA-regulated products) and 227,000+ problems the inspectors found. The fields include the facility owner, location, product type, inspection completion date, and outcomes. The records, which go back to fiscal year 2009, can be bulk-downloaded from the dashboard and queried via an API. They come with certain caveats; they exclude, for instance, “inspections waiting for a final enforcement action” and those conducted by state (rather than federal) inspectors. Related: More compliance-related data dashboards from the FDA.\n",
      "(Score: 0.5040) References:\n",
      "* https://datadashboard.fda.gov/ora/cd/inspections.htm\n",
      "* https://datadashboard.fda.gov/ora/api/index.htm\n",
      "* https://datadashboard.fda.gov/ora/cd/index.htm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter your question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "# Define the minimum similarity for a match\n",
    "MIN_SIM = 0.5\n",
    "\n",
    "while True:\n",
    "    # Ask for a question\n",
    "    question = input(\"\\nPlease enter your question (or type 'exit' to quit): \")\n",
    "    \n",
    "    if question.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    # Find and print closest matches\n",
    "    matches = find_closest_matches(question, embeddings, descriptions, links, 25)\n",
    "    print(\"\\nTop matches:\")\n",
    "    for i, (desc, score, link) in enumerate(matches, 1):\n",
    "        if score > MIN_SIM:\n",
    "            print(f\"\\n{i}. {desc}\\n(Score: {score:.4f}) References:\")\n",
    "            for r in link.split():\n",
    "                print(f\"* {r}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12602f6d-f3a8-49cd-8a97-30bbb8633eb1",
   "metadata": {},
   "source": [
    "## And with that, we wrap up for the moment...\n",
    "\n",
    "Don't forget to hit subscribe on the [What Can Data Do?](https://www.youtube.com/@whatcandatado?sub_confirmation=1) YouTube channel. Stay tuned for those succinct data nuggets tailor-made for the ever-busy data enthusiasts. In data, we trust!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
